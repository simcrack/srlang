:source-highlighter: rouge
:doctype: book
:toc:
:toc-title:  Inhalt
:author: Simon Reichenbach
:theme: adoc

= Semesterarbeit FAC
Simon Reichenbach

== Glossar

[options="header",cols="1,2"]
|===
| Begriff | Bedeutung
| PCRE    | https://de.wikipedia.org/wiki/Perl_Compatible_Regular_Expressions[Perl Compatible Regular Expression]
|===

== Beispielprogramm

[source,srlang]
----
r1 int := 123; //Variablendeklaration, Integer-Literal
ab str := "Test"; //Variablendeklaration, String-Literal
ac int := abc(r1); //Funktionsaufruf

fn a1(a int, bc str) int {
	//Funktion mit Integer-Rückgabe, ein Integer- und ein String-Argument
	ret(1);
}

fn abc(a int) {
	//Funktion ohne Rückgabewert, ein Integer-Argument
}

if (r1 == 123) {
	//Bedingte Anweisung
} el {

}

a := ((1 + r1) * 5) //Arithmetischer Ausdruck

lp (true) {
	//Endloser Loop
}
----

== Grammatik

=== Alphabet
Das Alphalbet der Grammatik beinhaltet folgende Zeichen (PCRE).

[source,pcre]
----
/[a-zA-Z0-9{}(),;:=\/*+"-]/
----

=== Tokens
In der folgenden Tabelle werden die vorbelegten Tokens als Reguläre Ausdrücke definiert.
Diese werden später für die Definition der Grammatik benötigt.

//Regex für Parser.cup "\| (.*?)\s*\| `/(.*)/" -> "terminal $1;\t// $2"
.geordnete Liste von Tokens
[options="header",cols="2,4"]
|===
| Terminal       | PCRE
| literalBoolean | `/(false\|true)/`
| literalInteger | `/[-+]{0,1}[0-9]+/`
| literalString  | `/"[^"]{0,256}"/`
|                | 
| kwAdd          | `/\+/`
| kwAssign       | `/:=/`
| kwCompare      | `/==/`
| kwCurlyClose   | `/\}/`
| kwCurlyOpen    | `/\{/`
| kwDiv          | `/\//`
| kwList         | `/,/`
| kwMul          | `/\*/`
| kwRoundClose   | `/\)/`
| kwRoundOpen    | `/\(/`
| kwSub          | `/-/`
|                | 
| kwEnd          | `/;/`
| kwElse         | `/el/`
| kwFunction     | `/fn/`
| kwIf           | `/if/`
| kwLoop         | `/lp/`
| kwReturn       | `/ret/`
|                | 
| comment        | `/\/\/[\n]*/`
| identifier     | `/[a-zA-z][a-zA-Z0-9]{0,255}/`
|===

<<<

=== Produktionen	
Kommentare werden nicht als Produktionen definiert, weil sie mittels eines Präprozessors aus dem Code entfernt werden.
Dadurch wird die Implementierung des Tokenizers deutlich vereinfacht.

Das Startsymbol ist: `Instructions`

[source,ebnf]
----
Instructions	= {Instruction}
			;
Instruction     = VariableDef
				| VariableAssign
				| FunctionDef
				| FunctionCall kwEnd	(* FunctionCall ist auch eine Expression, deshalb erst hier kwEnd *)
				| kwCurlyOpen Instructions kwCurlyClose
				| Conditional
			;

Literal			= literalInteger
				| literalString
				| literalBoolean
			;
Operator		= kwAdd
				| kwSub
				| kwMul
				| kwDiv
				| kwCompare
			;

Type			= identifier
			;
Variable		= identifier
			;
VariableDef		= Variable Type kwAssign Expression kwEnd
			;
VariableAssign	= Variable kwAssign Expression kwEnd
			;
Expression		= FunctionCall (* FunctionCall ist auch eine Instruction, dort wird noch ein kwEnd angehängt *)
				| Literal
				| Variable
				| Expression Operator Expression
				| kwRoundOpen Expression kwRoundClose
			;

ArgumentDef		= Variable Type
				| ArgumentDef kwList Variable Type
			;
ArgumentList	= Expression
				| ArgumentList kwList Expression
			;

FunctionName	= identifier
			;
FunctionCall	= FunctionName kwRoundOpen ArgumentList kwRoundClose
			;
FunctionDef		= kwFunction FunctionName kwRoundOpen ArgumentDef kwRoundClose kwCurlyOpen Instructions [kwReturn kwRoundOpen Expression kwRoundClose kwEnd]}"
			;

Conditional		= kwIf kwRoundOpen Expression kwRoundClose kwCurlyOpen Instructions kwCurlyClose [kwElse kwCurlyOpen Instructions kwCurlyClose]
			;
Loop			= kwLoop kwRoundOpen Expression kwRoundClose kwCurlyOpen Instructions kwCurlyClose
			;
----

